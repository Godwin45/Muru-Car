{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kfp\n",
    "import kfp.components as comp\n",
    "import requests\n",
    "import kfp.dsl as dsl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'mlProject'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmlProject\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m logger\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmlProject\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpipeline\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstage_01_data_ingestion\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataIngestionTrainingPipeline\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'mlProject'"
     ]
    }
   ],
   "source": [
    "from mlProject import logger\n",
    "import os\n",
    "from src.mlProject.pipeline.stage_01_data_ingestion import DataIngestionTrainingPipeline\n",
    "from src.mlProject.pipeline.stage_02_data_cleaning import DataCleaningPipeline\n",
    "from src.mlProject.pipeline.stage_03_data_validation import DataValidationTrainingPipeline\n",
    "from src.mlProject.pipeline.stage_04_data_transformation import DataTransformationTrainingPipeline\n",
    "from src.mlProject.pipeline.stage_05_model_trainer import ModelTrainerTrainingPipeline\n",
    "from src.mlProject.pipeline.stage_06_model_evaluation import ModelEvaluationTrainingPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_step_data_ingestion = kfp.components.create_component_from_func(\n",
    "    func=DataIngestionTrainingPipeline,\n",
    "    base_image='python:3.8',\n",
    "    packages_to_install=['pandas','numpy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_step_data_cleaning = kfp.components.create_component_from_func(\n",
    "    func=DataCleaningPipeline,\n",
    "    base_image='python:3.8',\n",
    "    packages_to_install=['pandas','numpy','scikit-learn']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_step_data_validation = kfp.components.create_component_from_func(\n",
    "    func=DataValidationTrainingPipeline,\n",
    "    base_image='python:3.8',\n",
    "    packages_to_install=['pandas','numpy','scikit-learn']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_step_data_transformation = kfp.components.create_component_from_func(\n",
    "    func=DataTransformationTrainingPipeline,\n",
    "    base_image='python:3.8',\n",
    "    packages_to_install=['pandas','numpy','scikit-learn']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_step_model_trainer = kfp.components.create_component_from_func(\n",
    "    func=ModelTrainerTrainingPipeline,\n",
    "    base_image='python:3.8',\n",
    "    packages_to_install=['pandas','numpy','scikit-learn']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_step_model_evaluation = kfp.components.create_component_from_func(\n",
    "    func=ModelEvaluationTrainingPipeline,\n",
    "    base_image='python:3.8',\n",
    "    packages_to_install=['pandas','numpy','scikit-learn']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the pipeline\n",
    "@dsl.pipeline(\n",
    "   name='Muru Logistic Engine Pipeline',\n",
    "   description='A  pipeline that performs Logistic Engine pipeline'\n",
    ")\n",
    "# Define parameters to be fed into pipeline\n",
    "def muru_logistic_pipeline(data_path: str):\n",
    "    vop = dsl.VolumeOp(\n",
    "    name=\"t-vol\",\n",
    "    resource_name=\"t-vol\", \n",
    "    size=\"2Gi\", \n",
    "    modes=dsl.VOLUME_MODE_RWO)\n",
    "   \n",
    "    data_ingestion = create_step_data_ingestion().add_pvolumes({data_path: vop.volume})\n",
    "    data_cleaning = create_step_data_cleaning().add_pvolumes({data_path: vop.volume}).after(data_ingestion)\n",
    "    data_validation = create_step_data_validation().add_pvolumes({data_path: vop.volume}).after(data_cleaning)\n",
    "    data_transformation = create_step_data_transformation().add_pvolumes({data_path: vop.volume}).after(data_validation)\n",
    "    model_trainer = create_step_model_trainer().add_pvolumes({data_path: vop.volume}).after(data_transformation)\n",
    "    model_evaluation = create_step_model_evaluation().add_pvolumes({data_path: vop.volume}).after(model_trainer)\n",
    "\n",
    "    \n",
    "    # prepare_data_task.execution_options.caching_strategy.max_cache_staleness = \"P0D\"\n",
    "    # train_test_split.execution_options.caching_strategy.max_cache_staleness = \"P0D\"\n",
    "    # classifier_training.execution_options.caching_strategy.max_cache_staleness = \"P0D\"\n",
    "    # log_predicted_class.execution_options.caching_strategy.max_cache_staleness = \"P0D\"\n",
    "    # log_predicted_probabilities.execution_options.caching_strategy.max_cache_staleness = \"P0D\"\n",
    "    # log_metrics_task.execution_options.caching_strategy.max_cache_staleness = \"P0D\"\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "kfp.compiler.Compiler().compile(\n",
    "    pipeline_func=muru_logistic_pipeline,\n",
    "    package_path='MURU_Logistic_pipeline.yaml')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = kfp.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '/data'\n",
    "\n",
    "import datetime\n",
    "print(datetime.datetime.now().date())\n",
    "\n",
    "\n",
    "pipeline_func = muru_logistic_pipeline\n",
    "experiment_name = 'muru_logistic_exp' +\"_\"+ str(datetime.datetime.now().date())\n",
    "run_name = pipeline_func.__name__ + ' run'\n",
    "namespace = \"kubeflow\"\n",
    "\n",
    "arguments = {\"data_path\":DATA_PATH}\n",
    "\n",
    "kfp.compiler.Compiler().compile(pipeline_func,  \n",
    "  '{}.zip'.format(experiment_name))\n",
    "\n",
    "run_result = client.create_run_from_pipeline_func(pipeline_func, \n",
    "                                                  experiment_name=experiment_name, \n",
    "                                                  run_name=run_name, \n",
    "                                                  arguments=arguments)\n",
    "\n",
    "# from kubernetes import client as k8s_client\n",
    "# pipeline_conf = kfp.dsl.PipelineConf()\n",
    "# pipeline_conf.set_image_pull_secrets([k8s_client.V1ObjectReference(namespace='kubeflow', \n",
    "#                                                                                  name=\"secret\")])\n",
    "# pipeline_conf.set_image_pull_policy(\"IfNotPresent\")\n",
    "    \n",
    "# Compile pipeline to generate compressed YAML definition of the pipeline.\n",
    "# kfp.compiler.Compiler().compile(pipeline_func,  \n",
    "#   '{}.zip'.format(experiment_name))\n",
    "\n",
    "# Submit pipeline directly from pipeline function\n",
    "# run_result = client.create_run_from_pipeline_func(pipeline_func, \n",
    "#                                                   experiment_name=experiment_name, \n",
    "#                                                   run_name=run_name, \n",
    "#                                                   arguments=arguments,\n",
    "#                                                   namespace = namespace,\n",
    "#                                                   pipeline_conf=pipeline_conf)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://www.youtube.com/watch?v=TBXJownrn7A"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
