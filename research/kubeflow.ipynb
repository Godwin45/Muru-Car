{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\pcx\\\\Desktop\\\\Projects\\\\muru1\\\\Muru-Car\\\\research'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kfp\n",
    "import kfp.components as comp\n",
    "import requests\n",
    "import kfp.dsl as dsl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlProject import logger\n",
    "import os\n",
    "from mlProject.pipeline.stage_01_data_ingestion import DataIngestionTrainingPipeline\n",
    "from mlProject.pipeline.stage_02_data_cleaning import DataCleaningPipeline\n",
    "from mlProject.pipeline.stage_03_data_validation import DataValidationTrainingPipeline\n",
    "from mlProject.pipeline.stage_04_data_transformation import DataTransformationTrainingPipeline\n",
    "from mlProject.pipeline.stage_05_model_trainer import ModelTrainerTrainingPipeline\n",
    "from mlProject.pipeline.stage_06_model_evaluation import ModelEvaluationTrainingPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_step_data_ingestion = kfp.components.create_component_from_func(\n",
    "    func=DataIngestionTrainingPipeline,\n",
    "    base_image='python:3.8',\n",
    "    packages_to_install=['pandas','numpy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_step_data_cleaning = kfp.components.create_component_from_func(\n",
    "    func=DataCleaningPipeline,\n",
    "    base_image='python:3.8',\n",
    "    packages_to_install=['pandas','numpy','scikit-learn']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_step_data_validation = kfp.components.create_component_from_func(\n",
    "    func=DataValidationTrainingPipeline,\n",
    "    base_image='python:3.8',\n",
    "    packages_to_install=['pandas','numpy','scikit-learn']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_step_data_transformation = kfp.components.create_component_from_func(\n",
    "    func=DataTransformationTrainingPipeline,\n",
    "    base_image='python:3.8',\n",
    "    packages_to_install=['pandas','numpy','scikit-learn']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_step_model_trainer = kfp.components.create_component_from_func(\n",
    "    func=ModelTrainerTrainingPipeline,\n",
    "    base_image='python:3.8',\n",
    "    packages_to_install=['pandas','numpy','scikit-learn']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_step_model_evaluation = kfp.components.create_component_from_func(\n",
    "    func=ModelEvaluationTrainingPipeline,\n",
    "    base_image='python:3.8',\n",
    "    packages_to_install=['pandas','numpy','scikit-learn']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the pipeline\n",
    "@dsl.pipeline(\n",
    "   name='Muru Logistic Engine Pipeline',\n",
    "   description='A  pipeline that performs Logistic Engine pipeline'\n",
    ")\n",
    "# Define parameters to be fed into pipeline\n",
    "def muru_logistic_pipeline(data_path: str):\n",
    "   \n",
    "    \n",
    "    data_ingestion = create_step_data_ingestion()\n",
    "    data_cleaning = create_step_data_cleaning().after(create_step_data_ingestion)\n",
    "    data_validation = create_step_data_validation().after(create_step_data_cleaning)\n",
    "    data_transformation = create_step_data_transformation().after(create_step_data_validation)\n",
    "    model_trainer = create_step_model_trainer().after(create_step_data_transformation)\n",
    "    model_evaluation = create_step_model_evaluation().after(create_step_model_trainer)\n",
    "\n",
    "    \n",
    "    # prepare_data_task.execution_options.caching_strategy.max_cache_staleness = \"P0D\"\n",
    "    # train_test_split.execution_options.caching_strategy.max_cache_staleness = \"P0D\"\n",
    "    # classifier_training.execution_options.caching_strategy.max_cache_staleness = \"P0D\"\n",
    "    # log_predicted_class.execution_options.caching_strategy.max_cache_staleness = \"P0D\"\n",
    "    # log_predicted_probabilities.execution_options.caching_strategy.max_cache_staleness = \"P0D\"\n",
    "    # log_metrics_task.execution_options.caching_strategy.max_cache_staleness = \"P0D\"\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute 'name'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m kfp\u001b[39m.\u001b[39;49mcompiler\u001b[39m.\u001b[39;49mCompiler()\u001b[39m.\u001b[39;49mcompile(\n\u001b[0;32m      2\u001b[0m     pipeline_func\u001b[39m=\u001b[39;49mmuru_logistic_pipeline,\n\u001b[0;32m      3\u001b[0m     package_path\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mMURU_Logistic_pipeline.yaml\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\pcx\\AppData\\Local\\anaconda3\\envs\\credit\\lib\\site-packages\\kfp\\compiler\\compiler.py:1175\u001b[0m, in \u001b[0;36mCompiler.compile\u001b[1;34m(self, pipeline_func, package_path, type_check, pipeline_conf)\u001b[0m\n\u001b[0;32m   1173\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1174\u001b[0m     kfp\u001b[39m.\u001b[39mTYPE_CHECK \u001b[39m=\u001b[39m type_check\n\u001b[1;32m-> 1175\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_create_and_write_workflow(\n\u001b[0;32m   1176\u001b[0m         pipeline_func\u001b[39m=\u001b[39;49mpipeline_func,\n\u001b[0;32m   1177\u001b[0m         pipeline_conf\u001b[39m=\u001b[39;49mpipeline_conf,\n\u001b[0;32m   1178\u001b[0m         package_path\u001b[39m=\u001b[39;49mpackage_path)\n\u001b[0;32m   1179\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m   1180\u001b[0m     kfp\u001b[39m.\u001b[39mTYPE_CHECK \u001b[39m=\u001b[39m type_check_old_value\n",
      "File \u001b[1;32mc:\\Users\\pcx\\AppData\\Local\\anaconda3\\envs\\credit\\lib\\site-packages\\kfp\\compiler\\compiler.py:1227\u001b[0m, in \u001b[0;36mCompiler._create_and_write_workflow\u001b[1;34m(self, pipeline_func, pipeline_name, pipeline_description, params_list, pipeline_conf, package_path)\u001b[0m\n\u001b[0;32m   1218\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_create_and_write_workflow\u001b[39m(\u001b[39mself\u001b[39m,\n\u001b[0;32m   1219\u001b[0m                                pipeline_func: Callable,\n\u001b[0;32m   1220\u001b[0m                                pipeline_name: Text \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1223\u001b[0m                                pipeline_conf: dsl\u001b[39m.\u001b[39mPipelineConf \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   1224\u001b[0m                                package_path: Text \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1225\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Compile the given pipeline function and dump it to specified file\u001b[39;00m\n\u001b[0;32m   1226\u001b[0m \u001b[39m    format.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1227\u001b[0m     workflow \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_create_workflow(pipeline_func, pipeline_name,\n\u001b[0;32m   1228\u001b[0m                                      pipeline_description, params_list,\n\u001b[0;32m   1229\u001b[0m                                      pipeline_conf)\n\u001b[0;32m   1230\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_write_workflow(workflow, package_path)\n\u001b[0;32m   1231\u001b[0m     _validate_workflow(workflow)\n",
      "File \u001b[1;32mc:\\Users\\pcx\\AppData\\Local\\anaconda3\\envs\\credit\\lib\\site-packages\\kfp\\compiler\\compiler.py:1005\u001b[0m, in \u001b[0;36mCompiler._create_workflow\u001b[1;34m(self, pipeline_func, pipeline_name, pipeline_description, params_list, pipeline_conf)\u001b[0m\n\u001b[0;32m   1002\u001b[0m         args_list\u001b[39m.\u001b[39mappend(param)\n\u001b[0;32m   1004\u001b[0m \u001b[39mwith\u001b[39;00m dsl\u001b[39m.\u001b[39mPipeline(pipeline_name) \u001b[39mas\u001b[39;00m dsl_pipeline:\n\u001b[1;32m-> 1005\u001b[0m     pipeline_func(\u001b[39m*\u001b[39;49margs_list, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs_dict)\n\u001b[0;32m   1007\u001b[0m pipeline_conf \u001b[39m=\u001b[39m pipeline_conf \u001b[39mor\u001b[39;00m dsl_pipeline\u001b[39m.\u001b[39mconf  \u001b[39m# Configuration passed to the compiler is overriding. Unfortunately, it's not trivial to detect whether the dsl_pipeline.conf was ever modified.\u001b[39;00m\n\u001b[0;32m   1009\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_exit_handler(dsl_pipeline)\n",
      "Cell \u001b[1;32mIn[12], line 11\u001b[0m, in \u001b[0;36mmuru_logistic_pipeline\u001b[1;34m(data_path)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[39m@dsl\u001b[39m\u001b[39m.\u001b[39mpipeline(\n\u001b[0;32m      3\u001b[0m    name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mMuru Logistic Engine Pipeline\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m      4\u001b[0m    description\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mA  pipeline that performs Logistic Engine pipeline\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m      5\u001b[0m )\n\u001b[0;32m      6\u001b[0m \u001b[39m# Define parameters to be fed into pipeline\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmuru_logistic_pipeline\u001b[39m(data_path: \u001b[39mstr\u001b[39m):\n\u001b[0;32m     10\u001b[0m     data_ingestion \u001b[39m=\u001b[39m create_step_data_ingestion()\n\u001b[1;32m---> 11\u001b[0m     data_cleaning \u001b[39m=\u001b[39m create_step_data_cleaning()\u001b[39m.\u001b[39;49mafter(create_step_data_ingestion)\n\u001b[0;32m     12\u001b[0m     data_validation \u001b[39m=\u001b[39m create_step_data_validation()\u001b[39m.\u001b[39mafter(create_step_data_cleaning)\n\u001b[0;32m     13\u001b[0m     data_transformation \u001b[39m=\u001b[39m create_step_data_transformation()\u001b[39m.\u001b[39mafter(create_step_data_validation)\n",
      "File \u001b[1;32mc:\\Users\\pcx\\AppData\\Local\\anaconda3\\envs\\credit\\lib\\site-packages\\kfp\\dsl\\_container_op.py:935\u001b[0m, in \u001b[0;36mBaseOp.after\u001b[1;34m(self, *ops)\u001b[0m\n\u001b[0;32m    933\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Specify explicit dependency on other ops.\"\"\"\u001b[39;00m\n\u001b[0;32m    934\u001b[0m \u001b[39mfor\u001b[39;00m op \u001b[39min\u001b[39;00m ops:\n\u001b[1;32m--> 935\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdependent_names\u001b[39m.\u001b[39mappend(op\u001b[39m.\u001b[39;49mname)\n\u001b[0;32m    936\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'function' object has no attribute 'name'"
     ]
    }
   ],
   "source": [
    "\n",
    "kfp.compiler.Compiler().compile(\n",
    "    pipeline_func=muru_logistic_pipeline,\n",
    "    package_path='MURU_Logistic_pipeline.yaml')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = kfp.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '/data'\n",
    "\n",
    "import datetime\n",
    "print(datetime.datetime.now().date())\n",
    "\n",
    "\n",
    "pipeline_func = iris_classifier_pipeline\n",
    "experiment_name = 'muru_logistic_exp' +\"_\"+ str(datetime.datetime.now().date())\n",
    "run_name = pipeline_func.__name__ + ' run'\n",
    "namespace = \"kubeflow\"\n",
    "\n",
    "arguments = {\"data_path\":DATA_PATH}\n",
    "\n",
    "kfp.compiler.Compiler().compile(pipeline_func,  \n",
    "  '{}.zip'.format(experiment_name))\n",
    "\n",
    "run_result = client.create_run_from_pipeline_func(pipeline_func, \n",
    "                                                  experiment_name=experiment_name, \n",
    "                                                  run_name=run_name, \n",
    "                                                  arguments=arguments)\n",
    "\n",
    "# from kubernetes import client as k8s_client\n",
    "# pipeline_conf = kfp.dsl.PipelineConf()\n",
    "# pipeline_conf.set_image_pull_secrets([k8s_client.V1ObjectReference(namespace='kubeflow', \n",
    "#                                                                                  name=\"secret\")])\n",
    "# pipeline_conf.set_image_pull_policy(\"IfNotPresent\")\n",
    "    \n",
    "# Compile pipeline to generate compressed YAML definition of the pipeline.\n",
    "# kfp.compiler.Compiler().compile(pipeline_func,  \n",
    "#   '{}.zip'.format(experiment_name))\n",
    "\n",
    "# Submit pipeline directly from pipeline function\n",
    "# run_result = client.create_run_from_pipeline_func(pipeline_func, \n",
    "#                                                   experiment_name=experiment_name, \n",
    "#                                                   run_name=run_name, \n",
    "#                                                   arguments=arguments,\n",
    "#                                                   namespace = namespace,\n",
    "#                                                   pipeline_conf=pipeline_conf)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "credit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
