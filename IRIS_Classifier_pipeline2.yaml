apiVersion: argoproj.io/v1alpha1
kind: Workflow
metadata:
  generateName: iris-classifier-csv-and-model-passing-
  annotations: {pipelines.kubeflow.org/kfp_sdk_version: 1.8.19, pipelines.kubeflow.org/pipeline_compilation_time: '2023-09-10T17:28:21.655971',
    pipelines.kubeflow.org/pipeline_spec: '{"description": "A sample pipeline that
      performs IRIS classifier task with csv passing between components", "inputs":
      [{"name": "target_column", "type": "String"}, {"name": "csv_url", "type": "String"}],
      "name": "IRIS classifier csv and model passing"}'}
  labels: {pipelines.kubeflow.org/kfp_sdk_version: 1.8.19}
spec:
  entrypoint: iris-classifier-csv-and-model-passing
  templates:
  - name: get-metrics
    container:
      args: [--trained-model, /tmp/inputs/trained_model/data, --test-csv, /tmp/inputs/test_csv/data,
        --y-pred-csv, /tmp/inputs/y_pred_csv/data, --target-column, '{{inputs.parameters.target_column}}']
      command:
      - sh
      - -c
      - (PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location
        'pandas==1.2.4' 'numpy==1.21.0' || PIP_DISABLE_PIP_VERSION_CHECK=1 python3
        -m pip install --quiet --no-warn-script-location 'pandas==1.2.4' 'numpy==1.21.0'
        --user) && "$0" "$@"
      - sh
      - -ec
      - |
        program_path=$(mktemp)
        printf "%s" "$0" > "$program_path"
        python3 -u "$program_path" "$@"
      - |
        def get_metrics(trained_model,
                       test_csv,
                       y_pred_csv,
                       target_column):
            import pandas as pd
            import numpy as np
            import pickle
            from sklearn.metrics import accuracy_score, precision_score, recall_score, log_loss
            from sklearn import metrics
            print("---- Inside get_metrics component ----")
            with open(test_csv) as f:
                test_df = pd.read_csv(f)

            with open(trained_model, 'rb') as f:
                logistic_reg_model = pickle.load(f)

            with open(y_pred_csv, 'rb') as f:
                y_pred_df = pd.read_csv(f)

            y_pred = y_pred_df.to_numpy()
            y_test = test_df.loc[:, test_df.columns == target_column]

            acc = accuracy_score(y_test, y_pred)
            prec = precision_score(y_test, y_pred, average='micro')
            recall = recall_score(y_test, y_pred, average='micro')

            print(metrics.classification_report(y_test, y_pred))

            print("\nModel Metrics:", {'accuracy': round(acc, 2), 'precision': round(prec, 2), 'recall': round(recall, 2)})

        import argparse
        _parser = argparse.ArgumentParser(prog='Get metrics', description='')
        _parser.add_argument("--trained-model", dest="trained_model", type=str, required=True, default=argparse.SUPPRESS)
        _parser.add_argument("--test-csv", dest="test_csv", type=str, required=True, default=argparse.SUPPRESS)
        _parser.add_argument("--y-pred-csv", dest="y_pred_csv", type=str, required=True, default=argparse.SUPPRESS)
        _parser.add_argument("--target-column", dest="target_column", type=str, required=True, default=argparse.SUPPRESS)
        _parsed_args = vars(_parser.parse_args())

        _outputs = get_metrics(**_parsed_args)
      image: python:3.7
    inputs:
      parameters:
      - {name: target_column}
      artifacts:
      - {name: train-test-split-test_csv, path: /tmp/inputs/test_csv/data}
      - {name: training-basic-classifier-trained_model, path: /tmp/inputs/trained_model/data}
      - {name: predict-on-test-data-y_pred_csv, path: /tmp/inputs/y_pred_csv/data}
    metadata:
      labels:
        pipelines.kubeflow.org/kfp_sdk_version: 1.8.19
        pipelines.kubeflow.org/pipeline-sdk-type: kfp
        pipelines.kubeflow.org/enable_caching: "true"
      annotations: {pipelines.kubeflow.org/component_spec: '{"implementation": {"container":
          {"args": ["--trained-model", {"inputPath": "trained_model"}, "--test-csv",
          {"inputPath": "test_csv"}, "--y-pred-csv", {"inputPath": "y_pred_csv"},
          "--target-column", {"inputValue": "target_column"}], "command": ["sh", "-c",
          "(PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location
          ''pandas==1.2.4'' ''numpy==1.21.0'' || PIP_DISABLE_PIP_VERSION_CHECK=1 python3
          -m pip install --quiet --no-warn-script-location ''pandas==1.2.4'' ''numpy==1.21.0''
          --user) && \"$0\" \"$@\"", "sh", "-ec", "program_path=$(mktemp)\nprintf
          \"%s\" \"$0\" > \"$program_path\"\npython3 -u \"$program_path\" \"$@\"\n",
          "def get_metrics(trained_model,\n               test_csv,\n               y_pred_csv,\n               target_column):\n    import
          pandas as pd\n    import numpy as np\n    import pickle\n    from sklearn.metrics
          import accuracy_score, precision_score, recall_score, log_loss\n    from
          sklearn import metrics\n    print(\"---- Inside get_metrics component ----\")\n    with
          open(test_csv) as f:\n        test_df = pd.read_csv(f)\n\n    with open(trained_model,
          ''rb'') as f:\n        logistic_reg_model = pickle.load(f)\n\n    with open(y_pred_csv,
          ''rb'') as f:\n        y_pred_df = pd.read_csv(f)\n\n    y_pred = y_pred_df.to_numpy()\n    y_test
          = test_df.loc[:, test_df.columns == target_column]\n\n    acc = accuracy_score(y_test,
          y_pred)\n    prec = precision_score(y_test, y_pred, average=''micro'')\n    recall
          = recall_score(y_test, y_pred, average=''micro'')\n\n    print(metrics.classification_report(y_test,
          y_pred))\n\n    print(\"\\nModel Metrics:\", {''accuracy'': round(acc, 2),
          ''precision'': round(prec, 2), ''recall'': round(recall, 2)})\n\nimport
          argparse\n_parser = argparse.ArgumentParser(prog=''Get metrics'', description='''')\n_parser.add_argument(\"--trained-model\",
          dest=\"trained_model\", type=str, required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"--test-csv\",
          dest=\"test_csv\", type=str, required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"--y-pred-csv\",
          dest=\"y_pred_csv\", type=str, required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"--target-column\",
          dest=\"target_column\", type=str, required=True, default=argparse.SUPPRESS)\n_parsed_args
          = vars(_parser.parse_args())\n\n_outputs = get_metrics(**_parsed_args)\n"],
          "image": "python:3.7"}}, "inputs": [{"name": "trained_model"}, {"name":
          "test_csv"}, {"name": "y_pred_csv"}, {"name": "target_column", "type": "String"}],
          "name": "Get metrics"}', pipelines.kubeflow.org/component_ref: '{}', pipelines.kubeflow.org/arguments.parameters: '{"target_column":
          "{{inputs.parameters.target_column}}"}', pipelines.kubeflow.org/max_cache_staleness: P0D}
  - name: iris-classifier-csv-and-model-passing
    inputs:
      parameters:
      - {name: csv_url}
      - {name: target_column}
    dag:
      tasks:
      - name: get-metrics
        template: get-metrics
        dependencies: [predict-on-test-data, train-test-split, training-basic-classifier]
        arguments:
          parameters:
          - {name: target_column, value: '{{inputs.parameters.target_column}}'}
          artifacts:
          - {name: predict-on-test-data-y_pred_csv, from: '{{tasks.predict-on-test-data.outputs.artifacts.predict-on-test-data-y_pred_csv}}'}
          - {name: train-test-split-test_csv, from: '{{tasks.train-test-split.outputs.artifacts.train-test-split-test_csv}}'}
          - {name: training-basic-classifier-trained_model, from: '{{tasks.training-basic-classifier.outputs.artifacts.training-basic-classifier-trained_model}}'}
      - name: predict-on-test-data
        template: predict-on-test-data
        dependencies: [train-test-split, training-basic-classifier]
        arguments:
          parameters:
          - {name: target_column, value: '{{inputs.parameters.target_column}}'}
          artifacts:
          - {name: train-test-split-test_csv, from: '{{tasks.train-test-split.outputs.artifacts.train-test-split-test_csv}}'}
          - {name: training-basic-classifier-trained_model, from: '{{tasks.training-basic-classifier.outputs.artifacts.training-basic-classifier-trained_model}}'}
      - name: prepare-data
        template: prepare-data
        arguments:
          parameters:
          - {name: csv_url, value: '{{inputs.parameters.csv_url}}'}
      - name: train-test-split
        template: train-test-split
        dependencies: [prepare-data]
        arguments:
          artifacts:
          - {name: prepare-data-output_csv, from: '{{tasks.prepare-data.outputs.artifacts.prepare-data-output_csv}}'}
      - name: training-basic-classifier
        template: training-basic-classifier
        dependencies: [train-test-split]
        arguments:
          parameters:
          - {name: target_column, value: '{{inputs.parameters.target_column}}'}
          artifacts:
          - {name: train-test-split-train_csv, from: '{{tasks.train-test-split.outputs.artifacts.train-test-split-train_csv}}'}
  - name: predict-on-test-data
    container:
      args: [--trained-model, /tmp/inputs/trained_model/data, --test-csv, /tmp/inputs/test_csv/data,
        --target-column, '{{inputs.parameters.target_column}}', --y-pred-csv, /tmp/outputs/y_pred_csv/data]
      command:
      - sh
      - -c
      - (PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location
        'pandas==1.2.4' 'numpy==1.21.0' || PIP_DISABLE_PIP_VERSION_CHECK=1 python3
        -m pip install --quiet --no-warn-script-location 'pandas==1.2.4' 'numpy==1.21.0'
        --user) && "$0" "$@"
      - sh
      - -ec
      - |
        program_path=$(mktemp)
        printf "%s" "$0" > "$program_path"
        python3 -u "$program_path" "$@"
      - |
        def _make_parent_dirs_and_return_path(file_path: str):
            import os
            os.makedirs(os.path.dirname(file_path), exist_ok=True)
            return file_path

        def predict_on_test_data(trained_model,
                                 test_csv,
                                 y_pred_csv,
                                 target_column):
            import pandas as pd
            import pickle

            print("---- Inside predict_on_test_data component ----")

            with open(test_csv, 'rb') as f:
                test_df = pd.read_csv(f)

            with open(trained_model, 'rb') as f:
                logistic_reg_model = pickle.load(f)
            target_column = target_column

            X_test = test_df.loc[:, test_df.columns != target_column]

            y_pred = logistic_reg_model.predict(X_test)
            y_pred_df = pd.DataFrame(y_pred)
            print(y_pred_df)

            with open(y_pred_csv, 'wb') as f:
                y_pred_df.to_csv(f, index=False)

        import argparse
        _parser = argparse.ArgumentParser(prog='Predict on test data', description='')
        _parser.add_argument("--trained-model", dest="trained_model", type=str, required=True, default=argparse.SUPPRESS)
        _parser.add_argument("--test-csv", dest="test_csv", type=str, required=True, default=argparse.SUPPRESS)
        _parser.add_argument("--target-column", dest="target_column", type=str, required=True, default=argparse.SUPPRESS)
        _parser.add_argument("--y-pred-csv", dest="y_pred_csv", type=_make_parent_dirs_and_return_path, required=True, default=argparse.SUPPRESS)
        _parsed_args = vars(_parser.parse_args())

        _outputs = predict_on_test_data(**_parsed_args)
      image: python:3.7
    inputs:
      parameters:
      - {name: target_column}
      artifacts:
      - {name: train-test-split-test_csv, path: /tmp/inputs/test_csv/data}
      - {name: training-basic-classifier-trained_model, path: /tmp/inputs/trained_model/data}
    outputs:
      artifacts:
      - {name: predict-on-test-data-y_pred_csv, path: /tmp/outputs/y_pred_csv/data}
    metadata:
      labels:
        pipelines.kubeflow.org/kfp_sdk_version: 1.8.19
        pipelines.kubeflow.org/pipeline-sdk-type: kfp
        pipelines.kubeflow.org/enable_caching: "true"
      annotations: {pipelines.kubeflow.org/component_spec: '{"implementation": {"container":
          {"args": ["--trained-model", {"inputPath": "trained_model"}, "--test-csv",
          {"inputPath": "test_csv"}, "--target-column", {"inputValue": "target_column"},
          "--y-pred-csv", {"outputPath": "y_pred_csv"}], "command": ["sh", "-c", "(PIP_DISABLE_PIP_VERSION_CHECK=1
          python3 -m pip install --quiet --no-warn-script-location ''pandas==1.2.4''
          ''numpy==1.21.0'' || PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install
          --quiet --no-warn-script-location ''pandas==1.2.4'' ''numpy==1.21.0'' --user)
          && \"$0\" \"$@\"", "sh", "-ec", "program_path=$(mktemp)\nprintf \"%s\" \"$0\"
          > \"$program_path\"\npython3 -u \"$program_path\" \"$@\"\n", "def _make_parent_dirs_and_return_path(file_path:
          str):\n    import os\n    os.makedirs(os.path.dirname(file_path), exist_ok=True)\n    return
          file_path\n\ndef predict_on_test_data(trained_model,\n                         test_csv,\n                         y_pred_csv,\n                         target_column):\n    import
          pandas as pd\n    import pickle\n\n    print(\"---- Inside predict_on_test_data
          component ----\")\n\n    with open(test_csv, ''rb'') as f:\n        test_df
          = pd.read_csv(f)\n\n    with open(trained_model, ''rb'') as f:\n        logistic_reg_model
          = pickle.load(f)\n    target_column = target_column\n\n    X_test = test_df.loc[:,
          test_df.columns != target_column]\n\n    y_pred = logistic_reg_model.predict(X_test)\n    y_pred_df
          = pd.DataFrame(y_pred)\n    print(y_pred_df)\n\n    with open(y_pred_csv,
          ''wb'') as f:\n        y_pred_df.to_csv(f, index=False)\n\nimport argparse\n_parser
          = argparse.ArgumentParser(prog=''Predict on test data'', description='''')\n_parser.add_argument(\"--trained-model\",
          dest=\"trained_model\", type=str, required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"--test-csv\",
          dest=\"test_csv\", type=str, required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"--target-column\",
          dest=\"target_column\", type=str, required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"--y-pred-csv\",
          dest=\"y_pred_csv\", type=_make_parent_dirs_and_return_path, required=True,
          default=argparse.SUPPRESS)\n_parsed_args = vars(_parser.parse_args())\n\n_outputs
          = predict_on_test_data(**_parsed_args)\n"], "image": "python:3.7"}}, "inputs":
          [{"name": "trained_model"}, {"name": "test_csv"}, {"name": "target_column",
          "type": "String"}], "name": "Predict on test data", "outputs": [{"name":
          "y_pred_csv"}]}', pipelines.kubeflow.org/component_ref: '{}', pipelines.kubeflow.org/arguments.parameters: '{"target_column":
          "{{inputs.parameters.target_column}}"}', pipelines.kubeflow.org/max_cache_staleness: P0D}
  - name: prepare-data
    container:
      args: [--csv-url, '{{inputs.parameters.csv_url}}', --output-csv, /tmp/outputs/output_csv/data]
      command:
      - sh
      - -c
      - (PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location
        'pandas==1.2.4' 'numpy==1.21.0' || PIP_DISABLE_PIP_VERSION_CHECK=1 python3
        -m pip install --quiet --no-warn-script-location 'pandas==1.2.4' 'numpy==1.21.0'
        --user) && "$0" "$@"
      - sh
      - -ec
      - |
        program_path=$(mktemp)
        printf "%s" "$0" > "$program_path"
        python3 -u "$program_path" "$@"
      - |
        def _make_parent_dirs_and_return_path(file_path: str):
            import os
            os.makedirs(os.path.dirname(file_path), exist_ok=True)
            return file_path

        def prepare_data(output_csv, csv_url):
            logging.basicConfig(level=logging.INFO)
            logger = logging.getLogger(__name__)

            df = pd.read_csv(csv_url)
            logger.info("Inside prepare data component")
            logger.debug(df.head())
            with open(output_csv, "w") as f:
                df.to_csv(f, index=False)

        import argparse
        _parser = argparse.ArgumentParser(prog='Prepare data', description='')
        _parser.add_argument("--csv-url", dest="csv_url", type=str, required=True, default=argparse.SUPPRESS)
        _parser.add_argument("--output-csv", dest="output_csv", type=_make_parent_dirs_and_return_path, required=True, default=argparse.SUPPRESS)
        _parsed_args = vars(_parser.parse_args())

        _outputs = prepare_data(**_parsed_args)
      image: python:3.7
    inputs:
      parameters:
      - {name: csv_url}
    outputs:
      artifacts:
      - {name: prepare-data-output_csv, path: /tmp/outputs/output_csv/data}
    metadata:
      labels:
        pipelines.kubeflow.org/kfp_sdk_version: 1.8.19
        pipelines.kubeflow.org/pipeline-sdk-type: kfp
        pipelines.kubeflow.org/enable_caching: "true"
      annotations: {pipelines.kubeflow.org/component_spec: '{"implementation": {"container":
          {"args": ["--csv-url", {"inputValue": "csv_url"}, "--output-csv", {"outputPath":
          "output_csv"}], "command": ["sh", "-c", "(PIP_DISABLE_PIP_VERSION_CHECK=1
          python3 -m pip install --quiet --no-warn-script-location ''pandas==1.2.4''
          ''numpy==1.21.0'' || PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install
          --quiet --no-warn-script-location ''pandas==1.2.4'' ''numpy==1.21.0'' --user)
          && \"$0\" \"$@\"", "sh", "-ec", "program_path=$(mktemp)\nprintf \"%s\" \"$0\"
          > \"$program_path\"\npython3 -u \"$program_path\" \"$@\"\n", "def _make_parent_dirs_and_return_path(file_path:
          str):\n    import os\n    os.makedirs(os.path.dirname(file_path), exist_ok=True)\n    return
          file_path\n\ndef prepare_data(output_csv, csv_url):\n    logging.basicConfig(level=logging.INFO)\n    logger
          = logging.getLogger(__name__)\n\n    df = pd.read_csv(csv_url)\n    logger.info(\"Inside
          prepare data component\")\n    logger.debug(df.head())\n    with open(output_csv,
          \"w\") as f:\n        df.to_csv(f, index=False)\n\nimport argparse\n_parser
          = argparse.ArgumentParser(prog=''Prepare data'', description='''')\n_parser.add_argument(\"--csv-url\",
          dest=\"csv_url\", type=str, required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"--output-csv\",
          dest=\"output_csv\", type=_make_parent_dirs_and_return_path, required=True,
          default=argparse.SUPPRESS)\n_parsed_args = vars(_parser.parse_args())\n\n_outputs
          = prepare_data(**_parsed_args)\n"], "image": "python:3.7"}}, "inputs": [{"name":
          "csv_url", "type": "String"}], "name": "Prepare data", "outputs": [{"name":
          "output_csv"}]}', pipelines.kubeflow.org/component_ref: '{}', pipelines.kubeflow.org/arguments.parameters: '{"csv_url":
          "{{inputs.parameters.csv_url}}"}', pipelines.kubeflow.org/max_cache_staleness: P0D}
  - name: train-test-split
    container:
      args: [--input-iris-csv, /tmp/inputs/input_iris_csv/data, --train-csv, /tmp/outputs/train_csv/data,
        --test-csv, /tmp/outputs/test_csv/data]
      command:
      - sh
      - -c
      - (PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location
        'pandas==1.2.4' 'numpy==1.21.0' || PIP_DISABLE_PIP_VERSION_CHECK=1 python3
        -m pip install --quiet --no-warn-script-location 'pandas==1.2.4' 'numpy==1.21.0'
        --user) && "$0" "$@"
      - sh
      - -ec
      - |
        program_path=$(mktemp)
        printf "%s" "$0" > "$program_path"
        python3 -u "$program_path" "$@"
      - |
        def _make_parent_dirs_and_return_path(file_path: str):
            import os
            os.makedirs(os.path.dirname(file_path), exist_ok=True)
            return file_path

        def train_test_split(input_iris_csv,
                             train_csv,
                             test_csv
                            ):
            import pandas as pd
            from sklearn.model_selection import train_test_split
            print("---- Inside train_test_split component ----")
            with open(input_iris_csv) as f:
                df = pd.read_csv(f)

            train_df, test_df = train_test_split(df, test_size=0.2, stratify=df['class'], random_state=47)
            print("\n train_df \n", train_df)
            print("\n test_df \n", test_df)

            with open(train_csv, "w") as f:
                train_df.to_csv(f, index=False)
            with open(test_csv, "w") as f:
                test_df.to_csv(f, index=False)

        import argparse
        _parser = argparse.ArgumentParser(prog='Train test split', description='')
        _parser.add_argument("--input-iris-csv", dest="input_iris_csv", type=str, required=True, default=argparse.SUPPRESS)
        _parser.add_argument("--train-csv", dest="train_csv", type=_make_parent_dirs_and_return_path, required=True, default=argparse.SUPPRESS)
        _parser.add_argument("--test-csv", dest="test_csv", type=_make_parent_dirs_and_return_path, required=True, default=argparse.SUPPRESS)
        _parsed_args = vars(_parser.parse_args())

        _outputs = train_test_split(**_parsed_args)
      image: python:3.7
    inputs:
      artifacts:
      - {name: prepare-data-output_csv, path: /tmp/inputs/input_iris_csv/data}
    outputs:
      artifacts:
      - {name: train-test-split-test_csv, path: /tmp/outputs/test_csv/data}
      - {name: train-test-split-train_csv, path: /tmp/outputs/train_csv/data}
    metadata:
      labels:
        pipelines.kubeflow.org/kfp_sdk_version: 1.8.19
        pipelines.kubeflow.org/pipeline-sdk-type: kfp
        pipelines.kubeflow.org/enable_caching: "true"
      annotations: {pipelines.kubeflow.org/component_spec: '{"implementation": {"container":
          {"args": ["--input-iris-csv", {"inputPath": "input_iris_csv"}, "--train-csv",
          {"outputPath": "train_csv"}, "--test-csv", {"outputPath": "test_csv"}],
          "command": ["sh", "-c", "(PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip
          install --quiet --no-warn-script-location ''pandas==1.2.4'' ''numpy==1.21.0''
          || PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location
          ''pandas==1.2.4'' ''numpy==1.21.0'' --user) && \"$0\" \"$@\"", "sh", "-ec",
          "program_path=$(mktemp)\nprintf \"%s\" \"$0\" > \"$program_path\"\npython3
          -u \"$program_path\" \"$@\"\n", "def _make_parent_dirs_and_return_path(file_path:
          str):\n    import os\n    os.makedirs(os.path.dirname(file_path), exist_ok=True)\n    return
          file_path\n\ndef train_test_split(input_iris_csv,\n                     train_csv,\n                     test_csv\n                    ):\n    import
          pandas as pd\n    from sklearn.model_selection import train_test_split\n    print(\"----
          Inside train_test_split component ----\")\n    with open(input_iris_csv)
          as f:\n        df = pd.read_csv(f)\n\n    train_df, test_df = train_test_split(df,
          test_size=0.2, stratify=df[''class''], random_state=47)\n    print(\"\\n
          train_df \\n\", train_df)\n    print(\"\\n test_df \\n\", test_df)\n\n    with
          open(train_csv, \"w\") as f:\n        train_df.to_csv(f, index=False)\n    with
          open(test_csv, \"w\") as f:\n        test_df.to_csv(f, index=False)\n\nimport
          argparse\n_parser = argparse.ArgumentParser(prog=''Train test split'', description='''')\n_parser.add_argument(\"--input-iris-csv\",
          dest=\"input_iris_csv\", type=str, required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"--train-csv\",
          dest=\"train_csv\", type=_make_parent_dirs_and_return_path, required=True,
          default=argparse.SUPPRESS)\n_parser.add_argument(\"--test-csv\", dest=\"test_csv\",
          type=_make_parent_dirs_and_return_path, required=True, default=argparse.SUPPRESS)\n_parsed_args
          = vars(_parser.parse_args())\n\n_outputs = train_test_split(**_parsed_args)\n"],
          "image": "python:3.7"}}, "inputs": [{"name": "input_iris_csv"}], "name":
          "Train test split", "outputs": [{"name": "train_csv"}, {"name": "test_csv"}]}',
        pipelines.kubeflow.org/component_ref: '{}', pipelines.kubeflow.org/max_cache_staleness: P0D}
  - name: training-basic-classifier
    container:
      args: [--train-csv, /tmp/inputs/train_csv/data, --target-column, '{{inputs.parameters.target_column}}',
        --trained-model, /tmp/outputs/trained_model/data]
      command:
      - sh
      - -c
      - (PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location
        'pandas==1.2.4' 'numpy==1.21.0' || PIP_DISABLE_PIP_VERSION_CHECK=1 python3
        -m pip install --quiet --no-warn-script-location 'pandas==1.2.4' 'numpy==1.21.0'
        --user) && "$0" "$@"
      - sh
      - -ec
      - |
        program_path=$(mktemp)
        printf "%s" "$0" > "$program_path"
        python3 -u "$program_path" "$@"
      - "def _make_parent_dirs_and_return_path(file_path: str):\n    import os\n \
        \   os.makedirs(os.path.dirname(file_path), exist_ok=True)\n    return file_path\n\
        \ndef training_basic_classifier(train_csv, \n                            \
        \  trained_model, \n                              target_column,\n       \
        \                      ):\n    import pandas as pd\n    from sklearn.linear_model\
        \ import LogisticRegression\n    import pickle\n\n    print(\"------- Inside\
        \ training_basic_classifier component -------\")\n\n    with open(train_csv)\
        \ as f:\n        train_df = pd.read_csv(f)\n    target_column = target_column\
        \   \n\n    X_train = train_df.loc[:, train_df.columns != target_column]\n\
        \    y_train = train_df.loc[:, train_df.columns == target_column]\n\n    classifier\
        \ = LogisticRegression(max_iter=500)\n    classifier.fit(X_train, y_train)\n\
        \n    with open(trained_model, 'wb') as f:\n        pickle.dump(classifier,\
        \ f)\n\n    print(\"\\nLogistic regression classifier is trained on iris data\
        \ .....\")\n\nimport argparse\n_parser = argparse.ArgumentParser(prog='Training\
        \ basic classifier', description='')\n_parser.add_argument(\"--train-csv\"\
        , dest=\"train_csv\", type=str, required=True, default=argparse.SUPPRESS)\n\
        _parser.add_argument(\"--target-column\", dest=\"target_column\", type=str,\
        \ required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"--trained-model\"\
        , dest=\"trained_model\", type=_make_parent_dirs_and_return_path, required=True,\
        \ default=argparse.SUPPRESS)\n_parsed_args = vars(_parser.parse_args())\n\n\
        _outputs = training_basic_classifier(**_parsed_args)\n"
      image: python:3.7
    inputs:
      parameters:
      - {name: target_column}
      artifacts:
      - {name: train-test-split-train_csv, path: /tmp/inputs/train_csv/data}
    outputs:
      artifacts:
      - {name: training-basic-classifier-trained_model, path: /tmp/outputs/trained_model/data}
    metadata:
      labels:
        pipelines.kubeflow.org/kfp_sdk_version: 1.8.19
        pipelines.kubeflow.org/pipeline-sdk-type: kfp
        pipelines.kubeflow.org/enable_caching: "true"
      annotations: {pipelines.kubeflow.org/component_spec: '{"implementation": {"container":
          {"args": ["--train-csv", {"inputPath": "train_csv"}, "--target-column",
          {"inputValue": "target_column"}, "--trained-model", {"outputPath": "trained_model"}],
          "command": ["sh", "-c", "(PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip
          install --quiet --no-warn-script-location ''pandas==1.2.4'' ''numpy==1.21.0''
          || PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location
          ''pandas==1.2.4'' ''numpy==1.21.0'' --user) && \"$0\" \"$@\"", "sh", "-ec",
          "program_path=$(mktemp)\nprintf \"%s\" \"$0\" > \"$program_path\"\npython3
          -u \"$program_path\" \"$@\"\n", "def _make_parent_dirs_and_return_path(file_path:
          str):\n    import os\n    os.makedirs(os.path.dirname(file_path), exist_ok=True)\n    return
          file_path\n\ndef training_basic_classifier(train_csv, \n                              trained_model,
          \n                              target_column,\n                             ):\n    import
          pandas as pd\n    from sklearn.linear_model import LogisticRegression\n    import
          pickle\n\n    print(\"------- Inside training_basic_classifier component
          -------\")\n\n    with open(train_csv) as f:\n        train_df = pd.read_csv(f)\n    target_column
          = target_column   \n\n    X_train = train_df.loc[:, train_df.columns !=
          target_column]\n    y_train = train_df.loc[:, train_df.columns == target_column]\n\n    classifier
          = LogisticRegression(max_iter=500)\n    classifier.fit(X_train, y_train)\n\n    with
          open(trained_model, ''wb'') as f:\n        pickle.dump(classifier, f)\n\n    print(\"\\nLogistic
          regression classifier is trained on iris data .....\")\n\nimport argparse\n_parser
          = argparse.ArgumentParser(prog=''Training basic classifier'', description='''')\n_parser.add_argument(\"--train-csv\",
          dest=\"train_csv\", type=str, required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"--target-column\",
          dest=\"target_column\", type=str, required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"--trained-model\",
          dest=\"trained_model\", type=_make_parent_dirs_and_return_path, required=True,
          default=argparse.SUPPRESS)\n_parsed_args = vars(_parser.parse_args())\n\n_outputs
          = training_basic_classifier(**_parsed_args)\n"], "image": "python:3.7"}},
          "inputs": [{"name": "train_csv"}, {"name": "target_column", "type": "String"}],
          "name": "Training basic classifier", "outputs": [{"name": "trained_model"}]}',
        pipelines.kubeflow.org/component_ref: '{}', pipelines.kubeflow.org/arguments.parameters: '{"target_column":
          "{{inputs.parameters.target_column}}"}', pipelines.kubeflow.org/max_cache_staleness: P0D}
  arguments:
    parameters:
    - {name: target_column}
    - {name: csv_url}
  serviceAccountName: pipeline-runner
